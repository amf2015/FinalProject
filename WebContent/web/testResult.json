[{"favoriteCount":0,"answerCount":0,"tagList":["reference-request","optimization","compilers"],"tags":"reference-request optimization compilers ","postTitle":"Constraint solving for scheduling code with complex unspillable register classes?","ownerUserId":44592,"postBody":"I\u0027m currently working on a compiler backend for a custom architecture which has some unusual constraints. The architecture has several super-registers with aliasing between the sub-registers, and none of these special registers can be spilled to memory. The code is initially constructed to ensure that registers can be allocated within these constraints (only one of the super-registers is live at a time).\n\nInstruction scheduling (which is done before register allocation) must ensure that it only generates instruction sequences that have a valid register allocation.\n\nAfter researching register allocation, it seems that the best fit for register allocation on my \u0027irregular architecture\u0027 is PBQP (partitioned boolean quadratic programming). However, during instruction scheduling, I don\u0027t need an (approximately) optimal register allocation, but rather just need to know whether there are any valid register allocations for a sequence of instructions.\n\nAdditionally, during scheduling, I\u0027m going to need to repeatedly solve many similar instances of the CSP (constraint satisfaction problem). Any time register allocation is not possible, I\u0027ll need to try the problem again with only a few different nodes/edges (for a different instruction), and each time the CSP is satisfied, I\u0027ll need to solve it again with a few additional nodes/edges (for the next instruction).\n\nI have not found any literature on solving similar CSPs taking advantage of the similarity, and the best algorithm I\u0027ve found for solving PBQP approximately (from Nearly optimal register allocation with PBQP) destructively modifies the graph while solving.\n\nIs there a better approach to use for testing register allocatability during instruction scheduling than PBQP, or is there a better algorithm for sequentially solving similar PBQP instances with only zero/infinite costs?\n","viewCount":61,"score":2,"creationDate":"2016-01-07T16:26:03.260","acceptedAnswerId":0,"postTypeId":1,"postId":51832},{"favoriteCount":1,"answerCount":3,"tagList":["time-complexity","memory-allocation","operating-systems"],"tags":"time-complexity memory-allocation operating-systems ","postTitle":"Clever memory management with constant time operations?","ownerUserId":68,"postBody":"Let\u0027s consider a memory segment (whose size can grow or shrink, like a file, when needed) on which you can perform two basic memory allocation operations involving fixed size blocks:\n\n\nallocation of one block\nfreeing a previously  allocated block which is not used anymore.\n\n\nAlso, as a requirement, the memory management system is not allowed to move around currently allocated blocks: their index/address must remain unchanged.\n\nThe most naive memory management algorithm would increment a global counter (with initial value 0) and use its new value as an address for the next allocation.\nHowever this will never allow to shorten the segment when only a few allocated blocks remain.\n\nBetter approach: Keep the counter, but maintain a list of deallocated blocks (which can be done in constant time) and use it as a source for new allocations as long as it\u0027s not empty.\n\nWhat next? Is there something clever that can be done, still with constraints of constant time allocation and deallocation, that would keep the memory segment as short as possible?\n\n(A goal could be to track the currently non-allocated block with the smallest address, but it doesn\u0027t seem to be feasible in constant time…)\n","viewCount":913,"score":16,"creationDate":"2012-03-06T21:46:27.713","acceptedAnswerId":69,"postTypeId":1,"postId":27},{"favoriteCount":0,"answerCount":1,"tagList":["programming-languages","compilers","operating-systems","memory-management","memory-allocation"],"tags":"programming-languages compilers operating-systems memory-management memory-allocation ","postTitle":"How Does Dynamic Heap Storage Have Something to Do with Heap?","ownerUserId":848,"postBody":"There are three typical ways to allocate memory for programs: static, stack and dynamic heap. However, when I look at the implementation of dynamic heap memory allocation from wikipedia , what I found is fixed block allocation, etc. So why is dynamic memory allocation called \"heap\" memory allocation? How does it have something to do with \"heap\"?\n","viewCount":78,"score":0,"creationDate":"2013-01-05T07:43:53.093","acceptedAnswerId":7783,"postTypeId":1,"postId":7776},{"favoriteCount":0,"answerCount":1,"tagList":["concurrency","database-theory"],"tags":"concurrency database-theory ","postTitle":"Compare-and-Swap in an RDBMS for custom locks and lock escalation","ownerUserId":762,"postBody":"I\u0027m applying the Compare-and-Swap technique to a SQL database to create custom row-level locking in my dataset, allowing for safe READ UNCOMMITTED isolation at the database level.\n\nThe Resource table includes a LockOwner GUID and a IsLocked BIT field.  To acquire a lock, a dirty-read query gets the ID, LockOwner, and LockStatus.  If Unlocked, attempt to UPDATE the Resource by (ID, LockOwner) with a newly generated LockOwner and LockStatus of Locked.  Abort and start again if no rows are updated - meaning someone else got there first.  Otherwise, the Lock is held in the READ UNCOMMITTED transaction.  The transaction is needed to allow rollback on client failure/abandon, but the dirty reads avoid locks.\n\nThis seems to me to work great for resources that are independent of each other.  But what must I add to account for a new kind of lock, ResourceGroup?\n\nResourceGroup to Resource is a one-to-many relationship.  Resources can be locked individually, but if the ResourceGroup needs to be locked, then all of the Resources must also be locked.  \n\nLocking a ResourceGroup is a far less frequent need than locking a Resource, so the scheme should be optimized for Resource queries, avoiding requiring joins to ResourceGroup if possible.\n\nI am imagining a scenario where locking a ResourceGroup involves marking the member rows with some flag, but I\u0027m not sure what scheme doesn\u0027t interfere with the original Resource-only scheme.  Part of the problem comes from the UPDATE of a Resource while it is locked (and therefore already UPDATED in another transaction).  I believe that even if the fields are different within the record, the UPDATE will place an UPDATE LOCK on the row, so any lock on ResourceGroup would introduce blocking that we are trying to avoid.  Even if we could do this, how would the ResourceGroup lock acquisition mechanism know when all of the Resources (which may have had locks in process as we began locking their peers) have been released?\n\nThere may be differences in this locking granularity by RDBMS, I\u0027m on MS SQL 2005+.\n","viewCount":283,"score":5,"creationDate":"2012-05-21T13:22:33.523","acceptedAnswerId":1994,"postTypeId":1,"postId":1974},{"favoriteCount":0,"answerCount":1,"tagList":["distributed-systems","performance","queueing-theory"],"tags":"distributed-systems performance queueing-theory ","postTitle":"What is the size of a queue associated with a resource when the resource becomes a bottleneck?","ownerUserId":22235,"postBody":"In Software Performance and Scalability: A Quantitative Approach - Henry H. Liu, the author is presenting a scenario where the hardware becomes a bottleneck. In one ot the tests, he is checking the number disk (read/write) operations. In particular, the number of disk writes as the number of threads increases (see figure below).\n\n\n\nAfter this, he states that: \"A rule of thumb is that a resource is a bottleneck when the queue length associated with it is over 2 per unit. Since the RAID 0 configuration used for this test had four disks, the threshold would be 8. This threshold of 8 had been exceeded with a\nwrite average queue length of 20 with 4 threads. With 16 threads, the associated average write queue length even went up to 132, which was over 16 times the threshold value of 8. It is clear that the system was disk write bottlenecked.\"\n\nMy question is: Why a resource is a bottleneck when its queue length is over 2? Why is not over 1? why is not over 1000000? why 2?\n","viewCount":85,"score":3,"creationDate":"2015-04-28T15:35:20.667","acceptedAnswerId":42021,"postTypeId":1,"postId":41919},{"favoriteCount":0,"answerCount":1,"tagList":["complexity-theory","time-complexity","approximation"],"tags":"complexity-theory time-complexity approximation ","postTitle":"Is it possible that low-resource Turing Machines can always \"usually\" agree with high-resource Turing Machines","ownerUserId":16172,"postBody":"Say that a language $L$ is a $f$-approximation of a language $L\u0027$ if, for all input lengths $n$, $L$ and $L\u0027$ agree on at least a fraction $f$ of the inputs.\n\nIt is known that there are problems in $TIME(n^{3})$ that are not in $TIME(n^2)$.  But is it possible that, for every language $L \\in TIME(n^{3})$, there is a $.99$ approximation in $TIME(n^2)$?\n\nI\u0027m also curious about this question with respect to other computational resources: Nondeterminstic Time, Space, and Randomness (although I\u0027m not even sure if there is a BPTIME hierarchy theorem, so it might be hard to answer for randomness).\n","viewCount":39,"score":2,"creationDate":"2015-05-16T08:56:51.407","acceptedAnswerId":0,"postTypeId":1,"postId":42628},{"favoriteCount":0,"answerCount":1,"tagList":["linear-programming","integer-programming","modelling"],"tags":"linear-programming integer-programming modelling ","postTitle":"Set Cover and additional constraints","ownerUserId":65584,"postBody":"Consider the following bipartite graph:\n\n\n\nEach node in red color represents a warehouse $w \u003d \\{ 1,2,3\\} $. For this example we have three warehouses located at different locations. Each warehouse has a cost of opening ${c_w} \u003d \\{ 7,8,10\\} $ for all $w$. In addition to that, each warehouse provides different resources ${r_1},{r_2}$ or ${r_3}$ required for stores that they have connection to be opened.\n\nEach node in blue color is a store $s \u003d \\{ 1,2,3,4,5\\} $. We have five stores for this example. Each store has its opening cost ${c_s} \u003d \\{ 9,11,12,10,8\\} $ for all $s$. In addition to that each store requires some resources that can be provided by one or more warehouses it is connected to. \n\nEach edge between store and warehouse has some cost. You can think about it as a distance from store location to a warehouse location. Thus, in order to open a store ${s_i}$ it should be connected to one or more warehouses which, together provide resources that ${s_i}$ needs.\n\nThe problem is to find a subset of possible warehouses, a subset of possible stores, and a plan to serve each open store by a list of connected open warehouses. Our goal is to compute the total profit from opened stores minus the total cost from opening warehouses and servicing open stores using those open warehouses is maximized.\n\nFor this example, the optimal plan:\n\n\nOpen $w \u003d 1$, provide ${r_1}$ to $s \u003d 1$, then open it.\nOpen $w \u003d 2$, provide $\\{ {r_1},{r_2}\\} $ to $s \u003d 2$, then open it.\nOpen $s \u003d 3$, by providing resources from $w \u003d \\{ 1,2\\} $\n\n\nThus, we opened 2 warehouses $w \u003d \\{ 1,2\\} $ that provided resources for $s \u003d \\{ 1,2,3\\} $, which we decided to open and we used only 4 edges. The optimal profit for this example is ${p_{OPT}} \u003d 9 + 11 + 12 - (7 + 8 + 3 + 3 + 3 + 4) \u003d 4$\n\nNow the task is to model this problem as mixed integer programming, more specifically i think using binary variables i have to define the objective function and all required constraints, also stating new variables.\n\nI have noticed that each ${r_s}$ can be considered a universe set and each ${r_w}$ or union of ${r_w}$s must cover ${r_s}$. This problem, was definitely, designed with a flavor of set covering. However, it was made more complicated by adding extra constraints. \n\nI need to model this problem as MIP. So far, i managed to determine the objective function and came up with some constraints that allow me to chose edges to warehouses that cover the store resources.\n\nMy objective function:\n$$\\max :\\sum\\nolimits_{i:s} {{c_s}} {z_i} - \\left( {\\sum\\nolimits_{j:w} {{c_w}{y_j} + \\sum\\nolimits_{k:e} {{c_e}{x_k}} } } \\right)$$where ${z_i},{y_j},{x_k}$ - binary values and ${c_e}$ is the cost of edge.\n\nOk, since this example is short i will write my objective function in expanded form so it becomes clear about my notation:\n\nMy objective function (expanded form):\n$\\max :9{z_0} + 11{z_1} + 12{z_2} + 10{z_3} + 8{z_4} - 7{y_0} - 8{y_1} - 10{y_2} - 3{x_{00}} - 5{x_{01}} - 3{x_{02}} - 3{x_{11}} - 4{x_{12}} - 5{x_{13}} - 7{x_{22}} - 6{x_{23}} - 4{x_{24}};$\n\n\n${z_i} \u003d 0$ if we don\u0027t open store $s \u003d i$ and ${z_i} \u003d 1$ otherwise\n${y_i} \u003d 0$ if we don\u0027t open warehouse $w \u003d i$ and ${y_i} \u003d 1$ otherwise\n${x_{ij}}$ means edge from store $j$ to warehouse $i$. \n${x_{ij}} \u003d 0$ if we don\u0027t use it and ${x_{ij}} \u003d 1$ otherwise\n\n\nNow i\u0027m trying to set the following constraints:\n\n\nFor each ${s_i}$, i consider ${r_{{s_i}}} \u003d U$ that is a universe set for which i should cover each element. \nThen i apply $\\sum\\nolimits_{S:v \\in S} {{y_S} \\ge 1,\\,\\,\\forall v \\in U} $, that is i pick 1 element from $U$ and determine which adjacent ${r_{{w_j}}}$ can cover it.\nFor each resource required by store, it is covered by one or more sets from 2.\nThen i ensure that store is opened if all of its resources are covered by reachable warehouse(s)\n\n\nHere is my constraint examples for $s \u003d 2 $.\n\nCase $s \u003d 2$:\n\nDenote ${y_{ij}}$ a warehouse $i$ resource set that covers first element from the resource set of store $j$, ${z_j}$ - opening store $j$, ${r_{kj}}$ - required resource ${r_k}$ from store $j$. All indexes starting from 0. Now i have \n\n$$\\begin{gathered}\n  {y_{01}} + {y_{11}} \\ge1; \\hfill \\\\\n  {y_{11}} \\ge 1; \\hfill \\\\\n  {r_{11}} \\le {y_{01}} + {y_{11}}; \\hfill \\\\\n  {r_{11}} \\ge {y_{01}}; \\hfill \\\\\n  {r_{11}} \\ge {y_{11}}; \\hfill \\\\\n  {r_{21}} \\le {y_{11}}; \\hfill \\\\\n  {r_{21}} \\ge {y_{11}}; \\hfill \\\\\n  {z_1} \\ge {r_{11}} + {r_{21}} - 1; \\hfill \\\\\n  {z_1} \\le {r_{11}}; \\hfill \\\\\n  {z_1} \\le {r_{21}}; \\hfill \\\\ \n\\end{gathered} $$\n\nIn a first line i determine that ${r_1}$ is contained in ${w_1}$ and ${w_2}$ sets. The second required resource ${r_2}$ is only in  ${w_2}$ set. Then i ensure that either one or both sets cover ${r_1}$ same with ${r_2}$. Finally i want to make sure that store can be opened if all resources can be supplied by warehouse. Now from this point i do something wrong because ${z_i}$ is always 1 if some reachable warehouse(s) can cover all resources. So basically with this encoding the solver always sets ${z_i}$ and i need to somehow link ${z_i}$ with warehouse opening. I guess instead of using ${z_i}$ to check if all resources can be obtained i need to introduce another dummy variable say $a$ and define a constraint something like: $a \\to {\\text{ some }}{w_i}$\n\nAs you can see from my constraints i\u0027m missing a link between ${z_i},{y_j},{x_{ij}}$. I managed to create a set of constraints that answer the question: Can any warehouse or their union cover all resources needed by some store. If they do ${z_i}$ is always set to 1 and i don\u0027t want it to be necessary set to 1 if the resource set is covered. What i need is to add some logic that will force the objective function to choose weather to open ${z_i}$ and what ${y_j}$ and ${x_{ij}}$ should be set to 0/1 in order to maximize the objective function.\n","viewCount":46,"score":0,"creationDate":"2017-03-27T23:24:50.240","acceptedAnswerId":72139,"postTypeId":1,"postId":72138},{"favoriteCount":0,"answerCount":1,"tagList":["algorithms","complexity-theory","optimization"],"tags":"algorithms complexity-theory optimization ","postTitle":"Minimizing transportation cost through a network, multiple source/sinks","ownerUserId":34021,"postBody":"I have the following problem:\n\n\n  Inputs:\n  \n  \n  A finite collection $V$ of vertices\n  A metric cost function $c:V^2\\to\\Bbb R$ (interpreted as the edge cost of a complete graph on $V$)\n  An amount of resource $s:V\\to\\Bbb R$ on each vertex, satisfying $\\sum_{u\\in V}s(u)\u003d0$\n  \n  \n  The problem is to determine a transfer function $f:V^2\\to\\Bbb R^{\\ge0}$ such that $\\sum_{v\\in V}(f(v,u)-f(u,v))\u003ds(u)$ for all $u$, which minimizes $\\sum_{u,v}f(u,v)c(u,v)$.\n\n\nThe story to tell is that the points represent places with some amount of resource (if $s(u)$ is positive) or with some need of the resource (if $s(u)$ is negative), and $c(u,v)$ is the cost of sending a unit of resource from $u$ to $v$. We assume that every vertex can send resource to any other vertex, and the direct path is usually better than passing through an intermediate point. How do we minimize the cost of sending everything from where it is to where it is needed?\n\nWhat is the name of this problem, and do there exist efficient algorithms to solve it? It seems similar to the minimum cost flow problem, but this only has one source and one sink, has maximum capacities for all the edges, and often needs multiple node paths for the resource, while here the direct path is always at least as good as a longer path (because the cost function is a metric).\n","viewCount":39,"score":3,"creationDate":"2017-02-19T01:01:30.157","acceptedAnswerId":70584,"postTypeId":1,"postId":70490},{"favoriteCount":0,"answerCount":0,"tagList":["continuations"],"tags":"continuations ","postTitle":"Playing with the Continuation Type","ownerUserId":58091,"postBody":"I hope this Q\u0026amp;A site is the correct place to ask this question; I\u0027ve been playing with the following familiar type:\n\n(a -\u0026gt; r) -\u0026gt; r\n\n\nAs you know, according to Yoneda Lemma, this is equivalent to a itself. Since this is equivalent to a, then we can say a -\u0026gt; ((b -\u0026gt; r) -\u0026gt; r) \u003d a -\u0026gt; (b -\u0026gt; r) -\u0026gt; r is then equivalent to a -\u0026gt; b\n\nI think this is standard issue for the continuation monad, but if we play with it in another direction, we can have other interesting results; for example we could say:\n\n(a, b) \u003d (a -\u0026gt; b -\u0026gt; r) -\u0026gt; r\nEither a b \u003d (a -\u0026gt; r, b -\u0026gt; r) -\u0026gt; r \u003d (a -\u0026gt; r) -\u0026gt; (b -\u0026gt; r) -\u0026gt; r\n\n\nI find what\u0027s going on here interesting because this has immediate applications in a language like, say C++, where it\u0027s annoying to work with product and sum types. So, if you need to return an Either a b (a + b) but you don\u0027t want to express that type, you can instead just accept a -\u0026gt; r and b -\u0026gt; r and return r. If your caller actually needs Either a b she can package it up herself with a suitable choice of r.\n\nAnd that\u0027s not limited to sum and product types either, for instance if you want to return a list of values, but if you don\u0027t want to get your hands dirty with memory allocation, you can instead resort to the definition of a list as:\n\nList a \u003d  Nil | a (List a)\nList a \u003d (r   , a -\u0026gt; r -\u0026gt; r) -\u0026gt; r \u003d r -\u0026gt; (a -\u0026gt; r -\u0026gt; r) -\u0026gt; r\n\n\nThat means instead of returning a list, you can instead accept an initial value and a fold. Again, if you\u0027re in C++, you either avoid memory allocation entirely if the caller will just fold the list with a known-size type or you will at least delegate the dirty work of memory allocation to her. This formulation easily extends to any algebraic data type using its catamorphism.\n\nThen I\u0027ve started wondering what you could do if you needed to return two lists. This is what I could come up with:\n\n(List a, List b) \u003d r1 -\u0026gt; (a -\u0026gt; r1 -\u0026gt; r1) -\u0026gt; (r1 -\u0026gt; r2) -\u0026gt; (b -\u0026gt; r2 -\u0026gt; r2) -\u0026gt; r2\n\n\nThat is, if you want to receive in1 as input and return two lists:\n\nin1 -\u0026gt; (List a, List b) \u003d in1 -\u0026gt; r1 -\u0026gt; (a -\u0026gt; r1 -\u0026gt; r1) -\u0026gt; (r1 -\u0026gt; r2) -\u0026gt; (b -\u0026gt; r2 -\u0026gt; r2) -\u0026gt; r2\n\n\nThis one looks a little bit trickier, but the initial r1 -\u0026gt; (a -\u0026gt; r1 -\u0026gt; r1) is for the first list, so you let the caller fold the first list. Then (r1 -\u0026gt; r2) is for starting the fold for the second list using the result of the first fold. The remaining (b -\u0026gt; r2 -\u0026gt; r2) -\u0026gt; r2 is for folding the second list.\n\nAt this point, I realize that there are a lot of variations that are equivalent to (List a, List b), and I\u0027m not even sure if my substitute for (List a, List b) is even a real equivalence, or if it\u0027s the most natural one in whatever sense. For instance, this is also an alternative:\n\n(List a, List b) \u003d r1 -\u0026gt; (a -\u0026gt; r1 -\u0026gt; r1) -\u0026gt; r2 -\u0026gt; (b -\u0026gt; r2 -\u0026gt; r2) -\u0026gt; (r1 -\u0026gt; r2 -\u0026gt; r) -\u0026gt; r\n\n\nSo, my question is: What the hell am I doing? I\u0027m quite sure much smarter people have explored these equivalences and I\u0027m sure they\u0027ve come up with very interesting results, could you provide any pointers to a formal analysis of this?\n","viewCount":21,"score":0,"creationDate":"2016-09-09T06:30:43.140","acceptedAnswerId":0,"postTypeId":1,"postId":63296},{"favoriteCount":0,"answerCount":2,"tagList":["algorithms","operating-systems","deadlocks"],"tags":"algorithms operating-systems deadlocks ","postTitle":"Bankers Algorithm-Is the system in safe state?","ownerUserId":56742,"postBody":"Could somebody please provide a step-through approach to solving the following problem using the Banker\u0027s Algorithm?\n\nA system contains 10 units of resource class Ru. The resource requirements of three user processes P1, P2 and P3 are as follows\n\n                      |   P1  |  P2  |   P3   |\nMax Requirement       |   8   |  7   |   5    |\nCurrent Allocation    |   3   |  1   |   3    |\nBalance Requirement   |   5   |  6   |   2    |\nNew Request Made      |   1   |  0   |   0    |\n\n\nUsing Banker’s algorithm, determine if the projected allocation state is safe and whether the request of P1 will be granted or not.\n\nMy solution:\n\ntotal recources :10\ntotal allocation :7\navailable: 10 -7 \u003d 3\n\nNeed \nP1     5\nP2     6\nP3     2\n\n3\u0026gt;2 so P3 can run now available is 6\n6\u0026gt;5 so P1 can run now availabl 9\n9\u0026gt;6 so P2 can run \n\n\nSystem is safe state,Hence P1 will be granted.\n\nBut I\u0027m not sure if my solution is true.\n","viewCount":730,"score":1,"creationDate":"2016-08-05T12:51:23.123","acceptedAnswerId":69760,"postTypeId":1,"postId":62320},{"favoriteCount":1,"answerCount":2,"tagList":["compilers","computer-architecture"],"tags":"compilers computer-architecture ","postTitle":"Theoretical minimum number of registers for a modern computer?","ownerUserId":5291,"postBody":"I took a course on compilers in my undergraduate studies in which we wrote a compiler that compiles source programs in a toy Java-like language to a toy assembly language (for which we had an interpreter). In the project we made some assumptions about the target machine closely related to \"real\" native executables, including:\n\n\na run-time stack, tracked by a dedicated stack pointer (\"SP\") register\na heap for dynamic object allocation, tracked by a dedicated heap pointer (\"HP\") register\na dedicated program counter register (\"PC\")\nthe target machine has 16 registers\noperations on data (as opposed to, e.g., jumps) are register-to-register operations\n\n\nWhen we got to the unit on using register allocation as an optimization, it made me wonder: What is the theoretical minimum number of registers for such a machine? You can see by our assumptions that we made use of five registers (SP, HP, PC, plus two for use as storage for binary operations) in our compiler. While optimizations like register allocation certainly can make use of more registers, is there a way to get by with fewer while still retaining structures like the stack and heap? I suppose with register addressing (register-to-register operations) we need at least two registers, but do we need more than two?\n","viewCount":1035,"score":9,"creationDate":"2013-01-15T06:31:34.123","acceptedAnswerId":0,"postTypeId":1,"postId":8941},{"favoriteCount":0,"answerCount":3,"tagList":["complexity-theory","algorithm-analysis"],"tags":"complexity-theory algorithm-analysis ","postTitle":"exponentially different running times random-access machine (RAM) vs Turing machine","ownerUserId":75191,"postBody":"I propose a simple polynomial algorithm for the following problem. Given $m$ integers each one stored on $n$ bits, output the integer that appears the most often.\n\n\nReserve a memory area with $2^n$ slots/registers/locations/cells, each cell being long enough to store the number $m$. This requires constant time because we do not initialize/touch the cells. If you agree with this, skip to step 2. Otherwise, check the following four points.\n\n\nOne could easily be tempted to read \"reserve a memory area\" as \"allocate a memory area\". Actually, the memory allocation operation is an invention/complication of real multi-tasking machines where programs can \"fight\" for memory. If I consider some (Random Access Machine) RAM machine that only knows running my algorithm, I can state that the algorithm can simply use the whole memory. Thus, it is enough to reserve (read \"put aside\" not \"allocate\") the first $2^n$ cells for a an array with $2^n$ elements. The next memory cells are simply used for other variables.    \nTo be more precise, I consider running my algorithm on a RAM-TM (Random Access Memory-Turing Machine) that is multi-tape TM with a memory and an index tape. Given a number written on the index tape, the RAM-TM takes constant time to move the head of the memory tape to the location indicated on the index tape. We also allow the RAM-TM to have a few other tapes for easily doing arithmetics. The RAM-TM has no notion of memory allocation. This seems to be a simplification of the various (Transdichotomous or word) RAM machines out there.\nEven if I must confess I do not really know the exact technical details of all theoretical machines RAM (or RASP), it is possible to work with an exponentially-large memory area and yet use only a polynomially large number of cells and my algorithm is not the first doing this. This also happens in the binary search algorithm over a sorted array: $n$ cells but only $O(log(n))$ time complexity. This scientific paper introduced a data structure that uses a large memory area but has constant time access, \nsee also the answer of zotachidil to this question. My algorithm could work with this data structure instead of explicitly reserving space.\nsee Ps 1.\n\nGo through the $m$ numbers in the input and for each one of them $x$ assign $[x]\u003d0$, where $[x]$ is the memory slot/location number $x$ in the above reserved memory area.\nGo through the $m$ numbers in the input and for each one of them $x$ assign $[x]\u003d[x]+1$.\nTake the first number $x$ in the input and assign $outVal\u003dx$ and $maxFreq\u003d[x]$. \nScan again the $m$ numbers and for each number $x$ perform: if $[x]\u0026gt;maxFreq$, set $outVal\u003dx$ and $maxFreq\u003d[x]$.\nOutput $outVal$.\n\n\nThe algorithm has time complexity $O(mn)$ assuming $n\\hskip 0.7mm \\not \\hskip -0.7mm \\ll m$ at least on the RAM-TM (see ps 2.), i.e., linear. It is certainly not the only algorithm to solve the problem, but I do not know any other linear algorithm using polynomial memory.\n\nHowever, the big problem is that the algorithm would require exponential time in a Turing machine, no? Does this contradict one of the Extended/Complexity-Theoretic Church–Turing Theses? The section \"Variations\" of the Wikipedia article on the Church–Turing thesis states that \"polynomial-time overhead and constant-space overhead could be simultaneously achieved for a simulation of a Random Access Machine on a Turing machine [55]\", where [55] is \"C. Slot, P. van Emde Boas, On tape versus core: an application of space efficient perfect hash functions to the invariance of space, STOC, December 1984\". Something seems inconsistent. Any help would be greatly appreciated. \n\nps 1. A real-machine argument for the fact one can allocate $O(2^n)$ bits in constant time. Notice I did not say the $2^n$ cells are initialized to some zero values. In a programming language like C this should be achieved by an instruction malloc instead of calloc. In my comment to D.W.\u0027s answer, I provide a reference for a real-life memory allocator that \"performs the allocation/deallocation in constant time\". However, D.W. seem to reject this argument, claiming the above \"constant time\" is calculated by ignoring the fact that we can have $n\\to \\infty$ since in practice $n$ does no go to $\\infty$, if I understood the response. As for me, it is hard to believe this \"constant time\" is actually $O(2^n)$, constant time is really far from $O(2^n)$. I would be surprised to see such large approximations in a paper published by Real-Time Systems. \n\nps 2. Not really essential, but a technical edit: because of Step 5, the complexity of the algorithm should be $O(nm+m\\cdot log(m))$ on a RAM-TM and not $O(nm)$, which is relevant only if $n$ is very very small compared to $m$. \n","viewCount":141,"score":2,"creationDate":"2017-07-20T21:05:58.200","acceptedAnswerId":0,"postTypeId":1,"postId":78145},{"favoriteCount":1,"answerCount":0,"tagList":["memory-management","virtual-memory","memory-access","memory-allocation"],"tags":"memory-management virtual-memory memory-access memory-allocation ","postTitle":"When there\u0027s no memory, should malloc or read/write fail?","ownerUserId":11551,"postBody":"To my surprise, I recently found out that Windows would fail a large memory allocation even if little of said memory is to actually be used, e.g. even if you don\u0027t want the swap, you better not disable it.  http://brandonlive.com/2010/02/21/measuring-memory-usage-in-windows-7/  (Basically, in Windows 7, Windows Task Manager, Performance, System, Commit, -- the sum of the physical memory plus the swap file is depicted, and a mere allocation of 2GB will immediately grow the figure by 2GB, unless such growth is restricted (e.g. if the page file is disabled), then the whole allocation would fail.)\n\nI recall that it\u0027s also the case with OpenVZ virtualisation, which behaves the same way, thus being incompatible with Java, for example.  However, I never really heard of anything like that in regards to the virtual memory of other operating systems, like FreeBSD, OpenBSD or non-OpenVZ Linux (which doesn\u0027t necessarily mean that they don\u0027t behave the same).\n\nWhat\u0027s the history behind such behaviour, and how the popular systems generally behave in such situation?  I mean, isn\u0027t virtual memory supposed to be unlimited on any system?\n","viewCount":155,"score":3,"creationDate":"2015-05-22T17:24:50.750","acceptedAnswerId":0,"postTypeId":1,"postId":42877},{"favoriteCount":0,"answerCount":2,"tagList":["deadlocks","resource-allocation"],"tags":"deadlocks resource-allocation ","postTitle":"Help interpreting this deadlock question","ownerUserId":38103,"postBody":"I have this assignment question but I am a bit unsure how to go about answering it. The question is as follows and accompanied by the image below: \n\nThree processes are competing for six resources labelled A to F as shown\nbelow.\n\n\n\nUsing a resource allocation graph, show the possibility of a deadlock in\nthe implementation above.\n\nI know how to do the graph but what I am struggling to understand is, do I take the Release(); methods into consideration or only the Get(); methods. And also, would P0() access resources A, B and C first or will each process run simultaneously meaning P0() access resource A, P1() access resource D and P2() access resource C, and then the second set of Get() methods are requested simultaneously? Lastly it does not specify how many instances (dots) are in each resource, is there any indication as to how to determine/go about working with this? As soon as I can clear up these misunderstandings I can draw the diagram\n","viewCount":707,"score":1,"creationDate":"2015-09-01T12:03:54.327","acceptedAnswerId":45770,"postTypeId":1,"postId":45764},{"favoriteCount":0,"answerCount":2,"tagList":["operating-systems","deadlocks"],"tags":"operating-systems deadlocks ","postTitle":"Falsifying the \"Circular Wait\" Condition - Deadlock Prevention","ownerUserId":11636,"postBody":"In the Circular Wait condition for Deadlock Prevention section of this, it is described as follows:\n\n\n  One\n  way to ensure that this condition never holds is to impose a total ordering of\n  all resource types and to require that each process requests resources in an\n  increasing order of enumeration.\n  To illustrate, we let R \u003d {R1, R2, ..., Rm} be the set of resource types. We\n  assign to each resource type a unique integer number, which allows us to\n  compare two resources and to determine whether one precedes another in our\n  ordering. Formally, we define a one-to-one function F: R → N, where N is the\n  set of natural numbers.\n  \n  For example, if the set of resource types R includes\n  tape drives, disk drives, and printers, then the function F might be defined as\n  follows:\n      F (tape drive) \u003d 1\n      F (disk drive) \u003d 5\n      F (printer) \u003d 12\n  We can now consider the following protocol to prevent deadlocks: Each\n  process can request resources only in an increasing order of enumeration.\n\n\nMy question is that whether these numbers are assigned as fixed for all processes or when each process is called, it assigns a new number to each resource each time that process is called?\n\nBecause if these are fixed, then let suppose there is a process which requires disk drive first (whose number is let\u0027s say 5) and then it requires tape drive (whose number is 1 and which is less than 5); then how can it access tape drive? Because whenever it will run, it will find the same ordering / numbering of resources and it will never be able to access the tape drive.\n","viewCount":974,"score":3,"creationDate":"2016-03-21T10:45:27.873","acceptedAnswerId":54736,"postTypeId":1,"postId":54732},{"favoriteCount":1,"answerCount":1,"tagList":["algorithms","machine-learning"],"tags":"algorithms machine-learning ","postTitle":"algorithm for predicting procces\u0027s memory/cpu usage based on other other prior/still running jobs","ownerUserId":48322,"postBody":"In a \u0027pool\u0027 with a lot of  cpus ,jobs(processes) are running(lots of them) . \n\nGiven I have  time/resource usage \u0027samples\u0027 from many prior/still running jobs - how would you go about trying to predict the process resource usage ?\n\nVery abstractly , what I think should be done is as follows :\n\n1) New job is submitted and start running and I wait for some time to gather resource usage information/samples\n\n2) find a subset of jobs that their  \u0027behave\u0027 (up until that point in running time) \u0027similarly\u0027 - how would u do that ? maybe those who are always in a specific margin and also there average distance is closest ?\n\n3) choose one job from the subset I found at stage 2, and give prediction of resource usage based upon that job..\n\nAre there known/standard way for my objective ? Would love to hear your ideas,direction etc ..\n","viewCount":323,"score":0,"creationDate":"2016-12-13T21:01:37.070","acceptedAnswerId":0,"postTypeId":1,"postId":67375},{"favoriteCount":0,"answerCount":0,"tagList":["concurrency"],"tags":"concurrency ","postTitle":"Identifying Coffman conditions in a given situation with deadlock","ownerUserId":59373,"postBody":"Let\u0027s suppose there are N processes and we have the following code:\n\natomic \u0026lt;int\u0026gt; c \u003d 0;\nsemaphore b \u003d 0;\n\nproc P(i){\n   ...\n   if(c.getAndInc() \u0026lt; N - 1){\n      b.wait();\n   }\n   else{\n      b.signal();\n   }\n   ...\n}\n\n\nA deadlock will occur as N - 2 processes will be blocked by $ b.wait() $.\nI\u0027m trying to identify how the Circular wait condition holds, being a necessary condition as it is.\n\n(Circular wait means that \"A set $\\{ P_0, P_1, ..., P_n \\}$ of waiting processes must exist such that $P_0$ is waiting for a resource held by $P_1$, $P_1$ is waiting for a resource held by $P_2$, ..., $P_{n-1}$ is waiting for a resource held by $P_n$, and $P_n$ is waiting for a resource held by $P_0$\". This quote is from the book \"Operating System Concepts\", by Silberschatz, Galvin and Gagne.)\n\nIn other words, as there is deadlock, the circular wait condition must hold, but I just don\u0027t see it. Is there anything I am misunderstanding?\n\nThanks!\n","viewCount":25,"score":2,"creationDate":"2017-08-01T21:17:27.650","acceptedAnswerId":0,"postTypeId":1,"postId":79587},{"favoriteCount":0,"answerCount":0,"tagList":["algorithms","cryptography","game-theory","one-way-functions"],"tags":"algorithms cryptography game-theory one-way-functions ","postTitle":"Understanding Incentive Compatibility of pooled Bitcoin Mining paper","ownerUserId":73951,"postBody":"I\u0027m trying to understand the paper Incentive Compatibility of\nBitcoin Mining Pool Reward Functions (Schrijvers, Bonneau, Doneh and Roughgarden, in Financial Cryptography and Data\nSecurity\u0026nbsp;\u0026ndash; FC 2016 Workshops, BITCOIN, 2016; PDF).\n\nIn page 3 Section 2.1, they say pool operator does not know actual $\\alpha_i$ mining power of player $i$. To estimate $\\alpha_i$ depends on the reported shares and solutions.\n\nA reward function $ R\\colon H \\mapsto [0,1]^n$ is a function from a history transcript to an allocation $ \\{a_i\\}_{i\u003d0} ^ {n} $ with $ \\sum_i a_i \u003d1 $. \nI don\u0027t understand this? What allocation does the authors mean?\n\nWhat I somewhat understand from next para is $ H(k) \u003d b \u003d (y_1(k), \\cdots, y_i(k) ) $ where $y_i(k)$ is no of shares reported by player $i$ in round $k$.\nThis I am basing on $H$ contains for each miner $i$ the total no of shares $b\n_i$ reported in that round. History transcript is given by a vector $b \\in N^n $.\n\nAlso what do they mean when they say \" We use vector notation for $b$, so $b_1 + b_2 $ means component wise addition of these, and  $\\|b\\|_1 \u003d \\sum_{i\u003d1}^n b_i $ is the sum of components of $b$\"\n\nCould someone explain with examples or in a more concrete way ?\nAlso any suggestions for understanding this paper would be much appreciated. Thanks.\n","viewCount":23,"score":2,"creationDate":"2017-06-21T13:33:23.327","acceptedAnswerId":0,"postTypeId":1,"postId":77062},{"favoriteCount":0,"answerCount":1,"tagList":["operating-systems","memory-management","virtual-memory"],"tags":"operating-systems memory-management virtual-memory ","postTitle":"Page management in OS kernels","ownerUserId":37588,"postBody":"I looked at some old OS theory books of mine and noticed that one glaring omission in all of these OS books is how to actually keep track of physical pages that are free (i.e. algorithms for actually implementing the free list). I know pretty well how userland memory allocators work, but a big difference with physical page allocation is that fragmentation of physical pages shouldn\u0027t be an issue, since the page table can just pick and choose the physical pages without having to care about whether they are contiguous or not. Since avoiding fragmentation is one of the main concerns of userland allocators, it seems like physical page allocation is fundamentally a different problem. I guess that this is not completely accurate if one wants to support superpages to reduce pressure on the TLB.\n\nMy question: What are techniques are used in modern high-performance kernels for this problem? Also, does this problem become significantly more complicated in NUMA systems?\n","viewCount":95,"score":7,"creationDate":"2015-08-18T20:32:10.010","acceptedAnswerId":0,"postTypeId":1,"postId":45381},{"favoriteCount":0,"answerCount":1,"tagList":["operating-systems","terminology","process-scheduling"],"tags":"operating-systems terminology process-scheduling ","postTitle":"Which queue does the long-term scheduler maintain?","ownerUserId":935,"postBody":"There are different queues of processes (in an operating system):\n\nJob Queue: Each new process goes into the job queue. Processes in the job queue reside on mass storage and await the allocation of main memory.\n\nReady Queue: The set of all processes that are in main memory and are waiting for CPU time is kept in the ready queue.\n\nWaiting (Device) Queues: The set of processes waiting for allocation of certain I/O devices is kept in the waiting (device) queue.\n\nThe short-term scheduler (also known as CPU scheduling) selects a process from the ready queue and yields control of the CPU to the process.\n\nIn my lecture notes the long-term scheduler is partly described as maintaining a queue of new processes waiting to be admitted into the system. \n\nWhat is the name of the queue the long-term scheduler maintains? When it admits a process to the system is the process placed in the ready queue?    \n","viewCount":5833,"score":4,"creationDate":"2012-04-07T06:24:48.613","acceptedAnswerId":1115,"postTypeId":1,"postId":1106},{"favoriteCount":0,"answerCount":1,"tagList":["memory-management","virtual-memory","memory-allocation"],"tags":"memory-management virtual-memory memory-allocation ","postTitle":"Why not space out memory allocations?","ownerUserId":55182,"postBody":"In ext4 file system, the files are spaced out as far apart as reasonably possible to allow for efficient reallocation. Why do we not do this in memory?\n\nWhy not allocate one memory as page 20, and the next large allocation as page 100 to allow for excess expansion before and after the current allocation? I feel that makes sense for large frequently changing-in-size buffers. For smaller buffers, doing so would probably be a drain on memory because we have to allocate each page for a small amount of bytes(but perhaps do it within a block too in the malloc impl). This would also provide greater memory corruption prevention, allowing segfaults(or windows equivalent) to happen quicker(specifically for larger buffers).\n\nWhy don\u0027t we do this? I get it on modern 32-bit systems because of limited address space, but why not on 64-bit?\n","viewCount":35,"score":2,"creationDate":"2016-07-23T00:32:01.283","acceptedAnswerId":60887,"postTypeId":1,"postId":60884},{"favoriteCount":4,"answerCount":3,"tagList":["operating-systems","concurrency","deadlocks"],"tags":"operating-systems concurrency deadlocks ","postTitle":"When do deadlocks occur?","ownerUserId":17040,"postBody":"I was reading about deadlocks in Operating Systems. Where I came across two examples below.\n\n\n  Circles with label $P_x$ are processes. Squares with label $R_x$ are resources.  Each dot in the square represents single instance of resource type $R_x$. An edge from $R_x$ to $P_x$ means an instance of resource $R_x$ is allocated to process $P_x$. An edge from $P_x$ to $R_x$ means the process $P_x$ is waiting for getting an instance of resource $R_x$ allocated.\n  \n  Now consider below two resource allocation graphs\n  \n  \n  \n  The example on left involves deadlock while the one on the right did not involved deadlock. \n\n\nI can understand that in right-side figure, if $P_2$ releases its instance of $R_1$, it can be assigned to $P_1$, breaking the circular wait. Or if $P_4$ release its instance of $R_2$, it can be assigned to $P_3$, breaking the circular wait. However we cannot break circular wait in left-side figure. \n\nWhile I can try out this on any given resource allocation graph and decide if there is deadlock or not, I want to know can we have a generalized rule for this which can tell what exactly it is which is contributing to the deadlock, especially in case of multiple instances of resources are there. I did not found any reference / book speaking of this clearly. So after a bit of thinking I came up with following fact:\n\n\n  If there are multiple instances of same resource, for deadlock to exist, for any combination of two processes, if both are allocated an instance of same resource, then both should be a part of at least one cycle.\n\n\nIn right-side figure above, there is no deadlock because \n\n\nprocesses $P_2$ and $P_3$ are allocated instances of $R_1$, but they both are not part of any cycle\nsimilarly processes $P_1$ and $P_4$ are allocated instances of $R_2$, but they both are not part of any cycle\n\n\nIn left-side figure above, there is a deadlock because\n\n\nprocesses $P_1$ and $P_2$ are allocated instances of resource $R_3$ and are part of same cycle,$P_1-R_1-P_2-R_3-P_3-R_3-P_1$\n\n\nSo am I correct with the above realization of fact? Or there are more aspects/conditions to the above fact (of when deadlock is present and when not) that I am missing?\n\nWhat I am asking is if there is any other condition which if met, instead of the above one, will still result in the deadlock (in the context of multiple instances of resources and apart from four classic conditions of deadlock: mutual exclusion, no preemption, hold and wait and circular wait)?\n","viewCount":340,"score":5,"creationDate":"2015-11-25T15:55:42.100","acceptedAnswerId":0,"postTypeId":1,"postId":49962},{"favoriteCount":0,"answerCount":1,"tagList":["complexity-theory","np-complete","np-hard","np"],"tags":"complexity-theory np-complete np-hard np ","postTitle":"Is this simple problem NP-complete?","ownerUserId":63415,"postBody":"Candy Allocation Problem: Suppose there are $n$ candies, each with a weight $w_i$ gram. There are $m$ kids, and each kid needs to eat at least $\\omega$ grams of candies to be full. Candies cannot be cut into pieces. Is there a candy allocation algorithm such that at least $k$ kids can be full?\n\nIs the above problem NP-complete? It has some similarity to knapsack, but not exactly the same. Can someone help me?\n","viewCount":182,"score":0,"creationDate":"2016-12-20T11:33:18.690","acceptedAnswerId":0,"postTypeId":1,"postId":67674},{"favoriteCount":0,"answerCount":0,"tagList":["algorithms"],"tags":"algorithms ","postTitle":"round robin algorithm with multiple iteration","ownerUserId":76482,"postBody":"I am working on a music synthesis. I have to generate certain musical notes and let us say total number of notes equals to $t$.\nI have $m$ number of methods (functions) named $m_1, m_2, m_3, \\cdots$ and each of them generate specific kind of musical phrases (group of musical notes) consisting of $x_n$ musical notes. \nLet us name these count of musical notes as $x_1, x_2, x_3,$ etc. corresponding to methods $m_1$, $m_2$ $m_3$ etc.\nThat means $t \u003d x_1+x_2+x_3+ \\dots  \u003d 100\\%$\nEach method is also associated with % allocation of musical notes they have to generate and $100\\%$ means $t$.\nOne method will not generate all required $x_n$ counts in one iteration and we may have to go for several iterations to reach their allocated $\\%$. \n\nAlso once one method is called, the same method cannot be called immediately unless it has very high %. So we need to go for round robin concept and I will name each iteration $i$. Also number of notes generated in each iteration by each method ($\u003dx_{ni}$) is known only after calling the method.\n\n$x_n \u003d x_{n1} + x_{n2} + x_{n3}+\\dots$ \n\nIt is assumed that number of notes in one iteration of respective method is always less than total allocated notes for that method ($x_{n_i} \u0026lt; x_n$)\n\nAssuming 3 methods, distribution could be something like:\n$t\u003d x_{11} + x_{21} + x_{31} + x_{12} + x_{32} + x_{13}+ x_{22} + x_{14} + x_{33} + x_{15} + x_{23} \u003d 100\\%$\nThat means every method may not be called in every iterations.\n\nSince number of notes generated by each method is known only after calling a method, we can not distribute in advance. After each iteration, we have to consolidate % notes distributed to that method and evaluate % allocation.\n\nI thought of using knapsack algorithm, considering total weight $\u003d 100\\% \u003d t$. But having difficulty with round robin distribution and due to iterative process. \n\nCan anyone suggest best algorithm to handle this? Also any support is available to code in Java?\n","viewCount":19,"score":0,"creationDate":"2017-08-25T18:10:33.740","acceptedAnswerId":0,"postTypeId":1,"postId":80439},{"favoriteCount":0,"answerCount":2,"tagList":["compilers"],"tags":"compilers ","postTitle":"What kind of language would you suggest for an University compiler project?","ownerUserId":35938,"postBody":"I\u0027m not an instructor. I\u0027m a student doing such course. And I\u0027m just trying to figure out what to do, because we\u0027re not given an input language. \n\n\n\nWhat kind of (input) language would you suggest for an University compiler project?\n\nIt\u0027s a project typical to the compiler course in CS programs.\n\nHowever, I\u0027ve been confused about, whether it would be easier to design a language for the project or use some existing programming language.\n\nIt should be able to handle the following requirements:\n\nReadable (no binary noodles)\nComments\nAt least two different types of data (type errors must be captured at the latest during the run)\nIntegrity technology\nMaking choices (if tms)\nPlayback (loops, recursion etc)\nParameterizable subroutines (functions, methods, etc) that can use local variables\n\n\nAdditional features\n\nTables (multidimensional, 0.5 cr, one-dimensional 0.25 cr)\nString input and output (0.25 cr)\nString interpolation or printf-style formatting by yourself (0.25 cr)\n    Complex printf formats (0.25 cr)\nRecords and variants (0.5 cr)\nGeneric (Static) Types (0.5 cr)\nClasses and Late Binding (0.5 cr)\nFirst-class functions (0.5 cr)\nGarbage collection (entirely self-made) (1 cr)\nRecursive pattern match (garden Haskell) (0.5 cr)\nLazy calculation (1-2 cr depending on the implementation technique)\n\n\nAdditionally the implementation would include:\n\nRelatively effective interpreter without separate intermediate language 0 cr\nGeneration of intermediate language (eg own, JVM or LLVM) 1 cr\nGeneration of a machine language (eg AMD64 or ARM) from its own intermediate language\nNaive register allocation 1 cr\nSmart register allocation (eg graphing) 2 cr\n\n\nAlso, what existing programming languages would fit into all of these? Does it have to be a functional language or does even C implement all of these?\n","viewCount":112,"score":0,"creationDate":"2017-04-21T10:21:48.527","acceptedAnswerId":0,"postTypeId":1,"postId":74296},{"favoriteCount":1,"answerCount":0,"tagList":["algorithms","algorithm-analysis","greedy-algorithms","intervals"],"tags":"algorithms algorithm-analysis greedy-algorithms intervals ","postTitle":"Why is it necessary to sort according to the starting time in the interval partitioning problem?","ownerUserId":58425,"postBody":"What is the problem if we sort the intervals according to their finishing time like the interval scheduling problem? Could someone give a counterexample\n?\n\nNote- (refer here for detailed definition)\n\nInterval Partioning Problem: Multiple Identical Resources are available and we have to partition all intervals across these resources using as few as possible. On each resource all intervals should be non overlapping.\n\nInterval Scheduling Problem: Only one resource is available. We have to maximise the number of non-overlapping intervals we can use on that single resource.\n","viewCount":81,"score":1,"creationDate":"2016-09-16T20:24:39.347","acceptedAnswerId":0,"postTypeId":1,"postId":63551},{"favoriteCount":0,"answerCount":1,"tagList":["concurrency","resource-allocation"],"tags":"concurrency resource-allocation ","postTitle":"Determining execution times of a concurrent system with exclusive resources","ownerUserId":21194,"postBody":"A certain system consists of 2 CPUs. The CPU that is not being used is assigned to a task whose execution is requested. On this system, two tasks, A and B, are executed.These tasks both use a common resource R exclusively.The CPU usage of the tasks A and B, the usage of resource R and the execution sequence are shown in the figure below.if both tasks are started at the same time, how long in ms will the completion of processing take for the two tasks?\n\n\n\na)120\n\nb)140\n\nc)150   \n\nd)200\n\nAccording to this question, I understand the resource R is used exclusively by the CPUs, mean if one is using it, the other has to wait. \n\nSo my answer is d :\n\n10 + 50 (first cpu) + 50(second cpu) + 60(first) + 30 (second) \u003d 200 \n\n\nBut the given answer is b, 140 : \n\n10 + 50 + 60 + 20 \u003d 140 ms \n\n\nI don\u0027t get it, could someone explain to me?\n\nAny help is greatly appreciated!\n","viewCount":36,"score":-3,"creationDate":"2014-08-28T09:12:02.760","acceptedAnswerId":29462,"postTypeId":1,"postId":29457},{"favoriteCount":2,"answerCount":1,"tagList":["distributed-systems"],"tags":"distributed-systems ","postTitle":"Does location transparency imply access transparency?","ownerUserId":31026,"postBody":"In distributed systems theory, I have found the definition that a distributed system requires, among others, location and access transparency.\n\nI was wondering if location transparency does not already include access transparency.\n\nWikipedia defines the two as follows:\n\n\n  Access transparency – Regardless of how resource access and representation has to be performed on each individual computing entity, the users of a distributed system should always access resources in a single, uniform way.\n  \n  Location transparency – Users of a distributed system should not have to be aware of where a resource is physically located.\n\n\nIf I am not to become aware of where a resource is physically located, doesn\u0027t that automatically imply that I have to be able to access all resources in a uniform way?\n\nIf yes, could you leave out access transparency from the definition without changing its meaning?\n","viewCount":359,"score":6,"creationDate":"2015-04-25T01:58:43.163","acceptedAnswerId":41828,"postTypeId":1,"postId":41814},{"favoriteCount":0,"answerCount":0,"tagList":["optimization","program-optimization"],"tags":"optimization program-optimization ","postTitle":"How to compute an optimally cost-effective cache strategy?","ownerUserId":9964,"postBody":"I am looking for advice in the following optimization problem. I have a website (system) that receives database updates later returned in queries made to the same system. In order to speed up the system the obvious solution is to cache data in different places. I have identified the most likely places where caching may be useful, but caching in every case is clearly not practical. I have begun to decompose the times it takes to place data in different caches. I will end up with.\n\nCu \u003d uth computation time\nSu \u003d storage required to store result of uth computation\nSCn \u003d storage cost using nth storage resource\nWn \u003d storage cache write time for nth storage resource\nRn \u003d storage cache read time for nth storage resource\n\n\nI understand that there are multiple caches inside today\u0027s microprocessors, but I want to ignore those for now. I actually have several options for storage. I can buy plenty of SSD, Spinning drives and/or RAM. But given the amount of possible caching I want to buy what makes most sense.\n\nI am trying to come up with a cost function, storage seems to be pretty straight forward since there will be an allocated space that will cost X dollars. I am struggling a bit more with timing. Clearly I could minimize the time it takes to query and update. But that does not seem correct. I need responsiveness, we need servers to be responsive with every request not to be able to process every single update and query at once in a couple of days, instead of three. I am constructing a $$ to seconds function. This function would imply, we are willing to pay $X for a computer that responds in Y seconds.\n\nI will also need an optimization algorithm, there are a lot out there and I am not sure which could be a good fit for this problem.\n\nI am having a lot of difficulty finding research similar to this description. And I do know I will need to redo this optimization a number of times, so I will end up writing code so I don\u0027t have to do this every time.\n","viewCount":137,"score":3,"creationDate":"2013-09-03T18:39:54.083","acceptedAnswerId":0,"postTypeId":1,"postId":14109},{"favoriteCount":0,"answerCount":1,"tagList":["optimization","reference-request","discrete-mathematics","matroids"],"tags":"optimization reference-request discrete-mathematics matroids ","postTitle":"What is a good resource to learn about oriented matroids in the context of digraphs and optimization?","ownerUserId":472,"postBody":"I am interested in oriented matroids in the context of directed graphs and optimization. Unfortunately, I know very little of the topic. Is there a book, article or a resource that serves as a good introduction to oriented matroids, especially in the context of directed graphs? It\u0027s a bonus if the resource is suitable for an (under)graduate level course and is preferably even free.\n","viewCount":80,"score":2,"creationDate":"2012-10-13T20:19:48.250","acceptedAnswerId":6047,"postTypeId":1,"postId":6046}]